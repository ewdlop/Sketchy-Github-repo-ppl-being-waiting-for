{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a97a8e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'ï¼' (U+FF01) (2863352914.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    æ­¡è¿ä¾†åˆ°é€™å€‹**è¶…ç´šè©­ç•°**çš„è¬è–ç¯€ç­†è¨˜æœ¬ï¼\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character 'ï¼' (U+FF01)\n"
     ]
    }
   ],
   "source": [
    "# ğŸƒ è©­ç•°è¬è–ç¯€ç‰¹è¼¯ ğŸ‘»\n",
    "\n",
    "æ­¡è¿ä¾†åˆ°é€™å€‹**è¶…ç´šè©­ç•°**çš„è¬è–ç¯€ç­†è¨˜æœ¬ï¼\n",
    "\n",
    "æº–å‚™å¥½è¿æ¥ä¸€äº›ä»¤äººæ¯›éª¨æ‚šç„¶çš„ç¨‹å¼ç¢¼äº†å—ï¼Ÿ ğŸ¦‡ğŸ•·ï¸ğŸ•¸ï¸\n",
    "\n",
    "---\n",
    "\n",
    "**è­¦å‘Šï¼š** é€™å€‹ç­†è¨˜æœ¬å¯èƒ½åŒ…å«ï¼š\n",
    "- ğŸ§Ÿ æ®­å±æ¼”ç®—æ³•\n",
    "- ğŸ‘» é¬¼é­‚å‹•ç•«\n",
    "- ğŸƒ å—ç“œé›•åˆ»è—è¡“\n",
    "- ğŸ¦‡ è™è ç¾¤é£›è¡Œæ¨¡æ“¬\n",
    "- ğŸ’€ éª¨æ¶ASCIIè—è¡“\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb17ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ‘» é¬¼é­‚ ASCII è—è¡“ç”Ÿæˆå™¨\n",
    "import time\n",
    "import random\n",
    "\n",
    "def haunted_ghost():\n",
    "    \"\"\"ç”Ÿæˆä¸€å€‹æœƒé£„å‹•çš„è©­ç•°é¬¼é­‚\"\"\"\n",
    "    ghosts = [\n",
    "        \"\"\"\n",
    "        .--.\n",
    "       /    \\\\\n",
    "      |  ğŸ‘»  |\n",
    "      |      |\n",
    "      |______|\n",
    "       ~ ~ ~\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        .--.\n",
    "       /    \\\\\n",
    "      |  ğŸ˜±  |\n",
    "      |      |\n",
    "      |______|\n",
    "      ~ ~ ~ ~\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        .--.\n",
    "       /    \\\\\n",
    "      |  ğŸ’€  |\n",
    "      |      |\n",
    "      |______|\n",
    "       ~ ~ ~\n",
    "        \"\"\"\n",
    "    ]\n",
    "    return random.choice(ghosts)\n",
    "\n",
    "# è®“é¬¼é­‚å‡ºç¾ï¼\n",
    "print(\"ğŸƒ è¬è–ç¯€å¿«æ¨‚ï¼é¬¼é­‚æ­£åœ¨å‡ºæ²’... ğŸƒ\\n\")\n",
    "for i in range(3):\n",
    "    print(haunted_ghost())\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef06b5",
   "metadata": {},
   "source": [
    "## ğŸƒ å—ç“œé›•åˆ»ç”Ÿæˆå™¨\n",
    "\n",
    "ä½¿ç”¨ç¨‹å¼ç¢¼ä¾†å‰µé€ ä½ è‡ªå·±çš„æ•¸ä½å—ç“œç‡ˆï¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸƒ å—ç“œç‡ˆè—è¡“\n",
    "def create_jack_o_lantern(mood=\"scary\"):\n",
    "    \"\"\"å‰µé€ ä¸åŒè¡¨æƒ…çš„å—ç“œç‡ˆ\"\"\"\n",
    "    \n",
    "    pumpkins = {\n",
    "        \"scary\": \"\"\"\n",
    "        â €â €â €â €â €â¢€â£ â£¤â£¤â£¤â£¤â£¤â£¤â£¤â£€â¡€â €â €â €â €â €\n",
    "        â €â €â¢€â£´â ¾â ›â ‰â €â €â €â €â €â €â ‰â ›â ·â£¦â¡€â €â €â €\n",
    "        â €â£°â Ÿâ â €â €â €â €â €â €â €â €â €â €â €â €â ˆâ »â£†â €â €\n",
    "        â¢°â¡Ÿâ €â €â£´â£†â €â €â €â €â €â €â €â €â£´â£†â €â €â¢»â¡†â €\n",
    "        â£¿â â €â €â ™â ‹â €â €â €â €â €â €â €â €â ™â ‹â €â €â ˆâ£¿â €\n",
    "        â£¿â €â €â €â €â €â¢€â£€â¡€â €â£¿â €â¢€â£€â¡€â €â €â €â €â£¿â €\n",
    "        â¢»â¡„â €â €â €â €â ˆâ ›â â €â €â €â ˆâ ›â â €â €â €â¢ â¡Ÿâ €\n",
    "        â €â »â£†â €â¢€â£€â£€â£€â£€â£€â£€â£€â£€â£€â£€â¡€â €â£°â Ÿâ €â €\n",
    "        â €â €â ˆâ »â£¦â£€â €â €â €â €â €â €â €â €â£€â£´â Ÿâ â €â €â €\n",
    "        â €â €â €â €â €â ‰â ›â ¶â ¶â ¶â ¶â ¶â ¶â ›â ‰â €â €â €â €â €â €\n",
    "        \"\"\",\n",
    "        \"happy\": \"\"\"\n",
    "        ğŸƒ å¿«æ¨‚å—ç“œç‡ˆ ğŸƒ\n",
    "        \n",
    "           ___________\n",
    "          /           \\\\\n",
    "         |  ^     ^    |\n",
    "         |   \\\\___/     |\n",
    "         |             |\n",
    "          \\\\___________ /\n",
    "             ||  ||\n",
    "        \"\"\",\n",
    "        \"evil\": \"\"\"\n",
    "        ğŸ’€ é‚ªæƒ¡å—ç“œç‡ˆ ğŸ’€\n",
    "        \n",
    "           ___________\n",
    "          /           \\\\\n",
    "         |  >     <    |\n",
    "         |      ^      |\n",
    "         |   \\\\_____/   |\n",
    "          \\\\___________ /\n",
    "             ||  ||\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    return pumpkins.get(mood, pumpkins[\"scary\"])\n",
    "\n",
    "# é¡¯ç¤ºä¸åŒè¡¨æƒ…çš„å—ç“œç‡ˆ\n",
    "print(\"ğŸƒ ææ€–çš„å—ç“œç‡ˆï¼š\")\n",
    "print(create_jack_o_lantern(\"scary\"))\n",
    "\n",
    "print(\"\\nğŸƒ é–‹å¿ƒçš„å—ç“œç‡ˆï¼š\")\n",
    "print(create_jack_o_lantern(\"happy\"))\n",
    "\n",
    "print(\"\\nğŸƒ é‚ªæƒ¡çš„å—ç“œç‡ˆï¼š\")\n",
    "print(create_jack_o_lantern(\"evil\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1faf67",
   "metadata": {},
   "source": [
    "## ğŸ¦‡ è™è æ´ç©´æ¨¡æ“¬å™¨\n",
    "\n",
    "æ¨¡æ“¬è™è åœ¨æ´ç©´ä¸­é£›è¡Œçš„è»Œè·¡ï¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1bc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¦‡ è™è æ´ç©´\n",
    "import random\n",
    "\n",
    "def bat_cave(num_bats=20):\n",
    "    \"\"\"ç”Ÿæˆè™è æ´ç©´çš„è¦–è¦ºæ•ˆæœ\"\"\"\n",
    "    cave = []\n",
    "    width = 50\n",
    "    \n",
    "    print(\"ğŸ•¸ï¸\" + \"=\" * width + \"ğŸ•¸ï¸\")\n",
    "    print(\"  ğŸ¦‡ æ­¡è¿ä¾†åˆ°è™è æ´ç©´ ğŸ¦‡\")\n",
    "    print(\"ğŸ•¸ï¸\" + \"=\" * width + \"ğŸ•¸ï¸\\n\")\n",
    "    \n",
    "    for i in range(10):\n",
    "        line = [' '] * width\n",
    "        # éš¨æ©Ÿæ”¾ç½®è™è \n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            pos = random.randint(0, width - 1)\n",
    "            line[pos] = 'ğŸ¦‡'\n",
    "        \n",
    "        # éš¨æ©Ÿæ”¾ç½®èœ˜è››ç¶²\n",
    "        for _ in range(random.randint(0, 2)):\n",
    "            pos = random.randint(0, width - 1)\n",
    "            if line[pos] == ' ':\n",
    "                line[pos] = 'ğŸ•¸ï¸'\n",
    "        \n",
    "        print(''.join(line))\n",
    "    \n",
    "    print(\"\\n\" + \"ğŸ’€\" * 10)\n",
    "\n",
    "bat_cave()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f66433",
   "metadata": {},
   "source": [
    "## ğŸ§™â€â™€ï¸ å¥³å·«çš„é­”è—¥é…æ–¹ç”Ÿæˆå™¨\n",
    "\n",
    "éš¨æ©Ÿç”Ÿæˆè©­ç•°çš„é­”è—¥é…æ–¹ï¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§™â€â™€ï¸ å¥³å·«çš„é­”è—¥\n",
    "import random\n",
    "\n",
    "def witch_potion():\n",
    "    \"\"\"ç”Ÿæˆéš¨æ©Ÿçš„é­”è—¥é…æ–¹\"\"\"\n",
    "    \n",
    "    ingredients = [\n",
    "        \"èœ˜è››è…¿\", \"è™è ç¿…è†€\", \"é’è›™çœ¼ç \", \"æ¯’è˜‘è‡\",\n",
    "        \"å¹½éˆç²¾è¯\", \"æ®­å±æŒ‡ç”²\", \"é»‘è²“æ¯›é«®\", \"è²“é ­é·¹ç¾½æ¯›\",\n",
    "        \"æ¯’è›‡ç‰™é½’\", \"è…çˆ›çš„å—ç“œ\", \"æœˆå…‰éœ²æ°´\", \"å¢“åœ’æ³¥åœŸ\"\n",
    "    ]\n",
    "    \n",
    "    effects = [\n",
    "        \"éš±å½¢\", \"é£›è¡Œ\", \"è®Šèº«\", \"é çŸ¥æœªä¾†\", \n",
    "        \"å¬å–šéˆé«”\", \"æ“æ§å½±å­\", \"å™©å¤¢èª˜ç™¼\", \"æ°¸ç”Ÿä¸æ­»\"\n",
    "    ]\n",
    "    \n",
    "    colors = [\"ç´«è‰²\", \"ç¶ è‰²\", \"é»‘è‰²\", \"è¡€ç´…è‰²\", \"é€æ˜\"]\n",
    "    \n",
    "    print(\"ğŸ§™â€â™€ï¸âœ¨ å¥³å·«çš„ç§˜å¯†é­”è—¥é…æ–¹ âœ¨ğŸ§™â€â™€ï¸\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"\\nğŸ“œ é­”è—¥åç¨±ï¼š{random.choice(effects)}è—¥æ°´\\n\")\n",
    "    print(\"ğŸ„ æ‰€éœ€ææ–™ï¼š\")\n",
    "    \n",
    "    num_ingredients = random.randint(3, 6)\n",
    "    selected = random.sample(ingredients, num_ingredients)\n",
    "    \n",
    "    for i, ingredient in enumerate(selected, 1):\n",
    "        amount = random.randint(1, 5)\n",
    "        print(f\"   {i}. {ingredient} x{amount}\")\n",
    "    \n",
    "    print(f\"\\nğŸ¨ è—¥æ°´é¡è‰²ï¼š{random.choice(colors)}\")\n",
    "    print(f\"ğŸ”® æ•ˆæœæŒçºŒï¼š{random.randint(1, 24)} å°æ™‚\")\n",
    "    print(\"\\nâš ï¸  è­¦å‘Šï¼šè«‹å‹¿åœ¨æœˆåœ“ä¹‹å¤œé£²ç”¨ï¼\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "# ç”Ÿæˆä¸‰ç¨®ä¸åŒçš„é­”è—¥\n",
    "for i in range(3):\n",
    "    witch_potion()\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b581b6",
   "metadata": {},
   "source": [
    "## ğŸ‘» é¬¼å±‹æ¢éšªéŠæˆ²\n",
    "\n",
    "ä¸€å€‹ç°¡å–®çš„æ–‡å­—å†’éšªéŠæˆ²ï¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ‘» é¬¼å±‹æ¢éšª\n",
    "import random\n",
    "\n",
    "class HauntedHouse:\n",
    "    def __init__(self):\n",
    "        self.rooms = {\n",
    "            \"å…¥å£å¤§å»³\": [\"ä½ çœ‹åˆ°äº†ä¸€å€‹å·¨å¤§çš„èœ˜è››ç¶²\", \"åœ°ä¸Šæœ‰å¥‡æ€ªçš„è…³å°\", \"åŠç‡ˆåœ¨æ–æ™ƒ\"],\n",
    "            \"å»šæˆ¿\": [\"é‹è£¡æ­£åœ¨ç…®è‘—å¯ç–‘çš„æ±è¥¿\", \"æ«¥æ«ƒè‡ªå·±æ‰“é–‹äº†\", \"è½åˆ°å¥‡æ€ªçš„ç¬‘è²\"],\n",
    "            \"è‡¥å®¤\": [\"åºŠä¸‹æœ‰æ±è¥¿åœ¨ç§»å‹•\", \"é¡å­è£¡å€’å½±ä¸å°å‹\", \"çª—ç°¾å¾Œé¢æœ‰å½±å­\"],\n",
    "            \"åœ°ä¸‹å®¤\": [\"ç‰†ä¸Šæœ‰è¡€è·¡\", \"è½åˆ°éµéˆè²\", \"çœ‹åˆ°ä¸€é›™ç™¼å…‰çš„çœ¼ç›\"],\n",
    "            \"é–£æ¨“\": [\"å¡µåœŸé£›æš\", \"ç™¼ç¾ä¸€æœ¬å¤è€çš„é­”æ³•æ›¸\", \"è™è å¾çª—æˆ¶é£›é€²ä¾†\"]\n",
    "        }\n",
    "        \n",
    "        self.monsters = [\"æ®­å±\", \"å¸è¡€é¬¼\", \"ç‹¼äºº\", \"é¬¼é­‚\", \"å¥³å·«\", \"éª·é«\"]\n",
    "    \n",
    "    def explore(self):\n",
    "        print(\"ğŸšï¸  æ­¡è¿ä¾†åˆ°è©­ç•°é¬¼å±‹ï¼ğŸšï¸ \")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"\\nä½ æ˜¯ä¸€åå‹‡æ•¢çš„æ¢éšªå®¶...\")\n",
    "        print(\"æº–å‚™æ¢ç´¢é€™æ£Ÿè¢«éºæ£„çš„é¬¼å±‹ï¼\\n\")\n",
    "        \n",
    "        for room_name, events in self.rooms.items():\n",
    "            print(f\"\\nğŸšª ä½ é€²å…¥äº†ã€{room_name}ã€‘...\")\n",
    "            print(f\"   {random.choice(events)}\")\n",
    "            \n",
    "            if random.random() > 0.5:\n",
    "                monster = random.choice(self.monsters)\n",
    "                print(f\"   âš ï¸  çªç„¶ï¼ä¸€å€‹{monster}å‡ºç¾äº†ï¼\")\n",
    "                \n",
    "                if random.random() > 0.3:\n",
    "                    print(f\"   âœ… ä½ æˆåŠŸé€ƒè„«äº†ï¼\")\n",
    "                else:\n",
    "                    print(f\"   ğŸ’€ ä½ è¢«{monster}åš‡æšˆäº†...\")\n",
    "                    print(f\"   ğŸƒ ä½ é©šæ…Œå¤±æªåœ°é€ƒå‡ºäº†é¬¼å±‹ï¼\")\n",
    "                    print(\"\\n\" + \"=\"*50)\n",
    "                    print(\"éŠæˆ²çµæŸï¼\")\n",
    "                    return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ğŸ‰ æ­å–œï¼ä½ æˆåŠŸæ¢ç´¢äº†æ•´æ£Ÿé¬¼å±‹ï¼\")\n",
    "        print(\"ä½ æ˜¯çœŸæ­£çš„å‹‡è€…ï¼ğŸ‘»ğŸ†\")\n",
    "\n",
    "# é–‹å§‹æ¢éšª\n",
    "game = HauntedHouse()\n",
    "game.explore()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a7f0b",
   "metadata": {},
   "source": [
    "## ğŸ•·ï¸ èœ˜è››ç¶²ç”Ÿæˆå™¨\n",
    "\n",
    "ç”¨ç¨‹å¼ç¢¼ç¹ªè£½è©­ç•°çš„èœ˜è››ç¶²ï¼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ•·ï¸ èœ˜è››ç¶²è—è¡“\n",
    "def draw_spider_web():\n",
    "    \"\"\"ç¹ªè£½ASCIIèœ˜è››ç¶²\"\"\"\n",
    "    \n",
    "    web = \"\"\"\n",
    "    â €â €â €â €â €â €â €â €â €â €â €â£€â£€â£€â €â €â €â €â €â €â €â €â €â €â €\n",
    "    â €â €â €â €â €â €â €â¢€â£ â£¶â£¿â£¿â£¿â£¿â£¿â£¶â£„â¡€â €â €â €â €â €â €â €\n",
    "    â €â €â €â €â €â¢€â£´â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¦â¡€â €â €â €â €â €\n",
    "    â €â €â €â €â£°â£¿â£¿â£¿â£¿â ¿â ¿â ¿â ¿â ¿â ¿â£¿â£¿â£¿â£¿â£¿â£†â €â €â €â €\n",
    "    â €â €â €â£¼â£¿â£¿â£¿â£¿â£¿â£¤â£¤â£¤â£¤â£¤â£¤â£¿â£¿â£¿â£¿â£¿â£¿â£§â €â €â €\n",
    "    â €â €â£¸â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿ğŸ•·ï¸â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¸â €â €\n",
    "    â €â¢ â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â¡„â €\n",
    "    â €â£¾â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£·â €\n",
    "    â €â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â €\n",
    "    â €â ¹â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â â €\n",
    "    â €â €â ™â¢¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â¡¿â ‹â €â €\n",
    "    â €â €â €â €â ™â »â¢¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â¡¿â Ÿâ ‹â €â €â €â €\n",
    "    â €â €â €â €â €â €â €â ˆâ ‰â ›â ›â ›â ›â ›â ›â ‰â â €â €â €â €â €â €â €\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ•¸ï¸ è©­ç•°çš„èœ˜è››ç¶² ğŸ•¸ï¸\")\n",
    "    print(web)\n",
    "    print(\"\\nâš ï¸  å°å¿ƒï¼èœ˜è››æ­£åœ¨ç­‰å¾…çµç‰©...\\n\")\n",
    "\n",
    "draw_spider_web()\n",
    "\n",
    "# é¡å¤–çš„èœ˜è››ç¶²åœ–æ¡ˆ\n",
    "print(\"\\n\" + \"ğŸ•¸ï¸ \" * 20)\n",
    "print(\"   \" * 5 + \"ğŸ•·ï¸ å…«éš»è…³çš„ææ€–ç”Ÿç‰©\")\n",
    "print(\"ğŸ•¸ï¸ \" * 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a6d6ab",
   "metadata": {},
   "source": [
    "## ğŸ­ è¬è–ç¯€çµèª\n",
    "\n",
    "æ„Ÿè¬ä½ é–±è®€é€™å€‹è©­ç•°çš„è¬è–ç¯€ç­†è¨˜æœ¬ï¼\n",
    "\n",
    "### ğŸƒ è¬è–ç¯€å°çŸ¥è­˜ï¼š\n",
    "- è¬è–ç¯€æºè‡ªå¤è€çš„å‡±çˆ¾ç‰¹ç¯€æ—¥ Samhain\n",
    "- Jack-o'-lantern æœ€åˆæ˜¯ç”¨è•ªèè£½ä½œçš„ï¼Œä¸æ˜¯å—ç“œï¼\n",
    "- ã€ŒTrick or Treatã€ï¼ˆä¸çµ¦ç³–å°±æ—è›‹ï¼‰å§‹æ–¼ 1920 å¹´ä»£\n",
    "\n",
    "---\n",
    "\n",
    "**ç¥ä½ è¬è–ç¯€å¿«æ¨‚ï¼ğŸ‘»ğŸƒğŸ¦‡**\n",
    "\n",
    "*è¨˜å¾—ï¼šåœ¨é€™å€‹ç‰¹åˆ¥çš„å¤œæ™šï¼Œæ€ªç‰©å’Œäººé¡å¯ä»¥å’Œå¹³å…±è™•...*\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8603619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§  è¶…è‡ªç„¶èªè¨€è™•ç† (Supernatural NLP) ç« ç¯€é–‹å§‹ï¼\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\" \" * 10 + \"ğŸ§™â€â™€ï¸ è¶…è‡ªç„¶èªè¨€è™•ç† ğŸ”®\")\n",
    "print(\" \" * 5 + \"Supernatural Natural Language Processing\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d5d4ce",
   "metadata": {},
   "source": [
    "## ğŸ‘» ç¬¬ä¸€èª²ï¼šå¹½éˆè©å‘é‡ (Ghost Word Vectors)\n",
    "\n",
    "**è©å‘é‡ (Word Embeddings)** æ˜¯ NLP ä¸­æœ€ç¥ç§˜çš„æ¦‚å¿µä¹‹ä¸€â€”â€”æŠŠæ–‡å­—è½‰æ›æˆæ•¸å­—å‘é‡ï¼Œå°±åƒæŠŠéˆé­‚å°å°é€²å®¹å™¨è£¡ï¼\n",
    "\n",
    "### ğŸ”® æ¦‚å¿µè§£é‡‹\n",
    "\n",
    "æƒ³åƒæ¯å€‹å–®è©éƒ½æ˜¯ä¸€å€‹**å¹½éˆ**ï¼Œå®ƒå€‘åœ¨é«˜ç¶­ç©ºé–“ä¸­æ¼‚æµ®ã€‚ç›¸ä¼¼çš„å¹½éˆæœƒèšé›†åœ¨ä¸€èµ·ï¼š\n",
    "- ã€Œæ®­å±ã€å’Œã€Œå¸è¡€é¬¼ã€çš„å¹½éˆå¾ˆæ¥è¿‘ï¼ˆéƒ½æ˜¯ä¸æ­»ç”Ÿç‰©ï¼‰\n",
    "- ã€Œå—ç“œã€å’Œã€Œè¬è–ç¯€ã€çš„å¹½éˆä¹Ÿæœƒåœ¨é™„è¿‘å¾˜å¾Š\n",
    "- ã€Œæ„›ã€å’Œã€Œæ¨ã€çš„å¹½éˆä½ç½®ç›¸åï¼Œä½†èƒ½é‡ç›¸è¿‘\n",
    "\n",
    "é€™å°±æ˜¯è©å‘é‡çš„é­”æ³•ï¼âœ¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ‘» å¹½éˆè©å‘é‡å¯¦ä½œ\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class GhostWordVector:\n",
    "    \"\"\"å¹½éˆè©å‘é‡é¡åˆ¥ - å°‡å–®è©è½‰æ›ç‚ºå‘é‡ç©ºé–“ä¸­çš„å¹½éˆ\"\"\"\n",
    "    \n",
    "    def __init__(self, dimension=3):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–å¹½éˆå‘é‡ç©ºé–“\n",
    "        dimension: å‘é‡ç¶­åº¦ï¼ˆ3D æ¯”è¼ƒå®¹æ˜“è¦–è¦ºåŒ–ï¼‰\n",
    "        \"\"\"\n",
    "        self.dimension = dimension\n",
    "        self.ghost_vault = {}  # å­˜æ”¾æ‰€æœ‰å¹½éˆçš„å¢“ç©´\n",
    "        \n",
    "    def summon_ghost(self, word):\n",
    "        \"\"\"å¬å–šä¸€å€‹æ–°çš„å¹½éˆï¼ˆå‰µå»ºè©å‘é‡ï¼‰\"\"\"\n",
    "        if word not in self.ghost_vault:\n",
    "            # ç‚ºæ¯å€‹å–®è©å‰µå»ºéš¨æ©Ÿå‘é‡ï¼ˆåœ¨çœŸå¯¦NLPä¸­æœƒç”¨è¨“ç·´å¥½çš„å‘é‡ï¼‰\n",
    "            vector = np.random.randn(self.dimension)\n",
    "            # æ­£è¦åŒ–å‘é‡ï¼ˆè®“å¹½éˆçš„èƒ½é‡æ¨™æº–åŒ–ï¼‰\n",
    "            vector = vector / np.linalg.norm(vector)\n",
    "            self.ghost_vault[word] = vector\n",
    "            print(f\"ğŸ‘» æˆåŠŸå¬å–šå¹½éˆï¼š'{word}'\")\n",
    "        else:\n",
    "            print(f\"âš ï¸  å¹½éˆ '{word}' å·²ç¶“å­˜åœ¨ï¼\")\n",
    "        \n",
    "        return self.ghost_vault[word]\n",
    "    \n",
    "    def ghost_similarity(self, word1, word2):\n",
    "        \"\"\"è¨ˆç®—å…©å€‹å¹½éˆçš„ç›¸ä¼¼åº¦ï¼ˆé¤˜å¼¦ç›¸ä¼¼åº¦ï¼‰\"\"\"\n",
    "        if word1 not in self.ghost_vault or word2 not in self.ghost_vault:\n",
    "            print(\"âŒ æœ‰äº›å¹½éˆé‚„æœªè¢«å¬å–šï¼\")\n",
    "            return None\n",
    "        \n",
    "        vec1 = self.ghost_vault[word1]\n",
    "        vec2 = self.ghost_vault[word2]\n",
    "        \n",
    "        # é¤˜å¼¦ç›¸ä¼¼åº¦ï¼šå‘é‡é»ç©\n",
    "        similarity = np.dot(vec1, vec2)\n",
    "        \n",
    "        return similarity\n",
    "    \n",
    "    def find_haunted_neighbors(self, word, top_n=3):\n",
    "        \"\"\"æ‰¾åˆ°èˆ‡æŒ‡å®šå¹½éˆæœ€æ¥è¿‘çš„å…¶ä»–å¹½éˆ\"\"\"\n",
    "        if word not in self.ghost_vault:\n",
    "            print(f\"âŒ å¹½éˆ '{word}' å°šæœªè¢«å¬å–šï¼\")\n",
    "            return []\n",
    "        \n",
    "        target_vector = self.ghost_vault[word]\n",
    "        similarities = {}\n",
    "        \n",
    "        for other_word, other_vector in self.ghost_vault.items():\n",
    "            if other_word != word:\n",
    "                similarity = np.dot(target_vector, other_vector)\n",
    "                similarities[other_word] = similarity\n",
    "        \n",
    "        # æ’åºä¸¦è¿”å›æœ€ç›¸ä¼¼çš„\n",
    "        sorted_ghosts = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_ghosts[:top_n]\n",
    "\n",
    "# ğŸƒ å¯¦é©—é–‹å§‹ï¼\n",
    "print(\"ğŸ”® å•Ÿå‹•å¹½éˆè©å‘é‡å¯¦é©—...\\n\")\n",
    "\n",
    "# å‰µå»ºå¹½éˆå‘é‡ç©ºé–“\n",
    "haunted_space = GhostWordVector(dimension=5)\n",
    "\n",
    "# å¬å–šè¬è–ç¯€ç›¸é—œçš„å¹½éˆ\n",
    "halloween_words = [\n",
    "    \"å—ç“œ\", \"é¬¼é­‚\", \"æ®­å±\", \"å¸è¡€é¬¼\", \"å¥³å·«\", \n",
    "    \"èœ˜è››\", \"è™è \", \"å¢“åœ°\", \"éª·é«\", \"é­”æ³•\",\n",
    "    \"é»‘è²“\", \"æƒå¸š\", \"é­”è—¥\", \"æœˆäº®\", \"é»‘å¤œ\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"å¬å–šå„€å¼é–‹å§‹...\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "for word in halloween_words:\n",
    "    haunted_space.summon_ghost(word)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"æ‰€æœ‰å¹½éˆå·²å°±ä½ï¼\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedde818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” æ¸¬è©¦å¹½éˆç›¸ä¼¼åº¦\n",
    "\n",
    "print(\"\\nğŸ”® æ¸¬è©¦å¹½éˆä¹‹é–“çš„é€£çµ...\\n\")\n",
    "\n",
    "test_pairs = [\n",
    "    (\"å—ç“œ\", \"è¬è–ç¯€\"),\n",
    "    (\"å¸è¡€é¬¼\", \"æ®­å±\"),\n",
    "    (\"å¥³å·«\", \"é­”æ³•\"),\n",
    "    (\"èœ˜è››\", \"è™è \"),\n",
    "    (\"é»‘è²“\", \"å¥³å·«\")\n",
    "]\n",
    "\n",
    "# ç‚ºäº†æ¼”ç¤ºï¼Œæˆ‘å€‘æ‰‹å‹•è¨­å®šä¸€äº›\"è¨“ç·´å¥½\"çš„å‘é‡\n",
    "# åœ¨çœŸå¯¦å ´æ™¯ä¸­ï¼Œé€™äº›å‘é‡æœƒé€éå¤§é‡æ–‡æœ¬è¨“ç·´å¾—åˆ°\n",
    "halloween_trained_vectors = {\n",
    "    \"å—ç“œ\": np.array([0.8, 0.6, 0.1, 0.3, 0.5]),\n",
    "    \"é¬¼é­‚\": np.array([0.2, 0.9, 0.8, 0.7, 0.1]),\n",
    "    \"æ®­å±\": np.array([0.3, 0.85, 0.7, 0.6, 0.2]),\n",
    "    \"å¸è¡€é¬¼\": np.array([0.25, 0.88, 0.75, 0.65, 0.15]),\n",
    "    \"å¥³å·«\": np.array([0.5, 0.6, 0.7, 0.8, 0.4]),\n",
    "    \"é­”æ³•\": np.array([0.45, 0.55, 0.65, 0.75, 0.35]),\n",
    "    \"èœ˜è››\": np.array([0.6, 0.4, 0.5, 0.3, 0.7]),\n",
    "    \"è™è \": np.array([0.55, 0.45, 0.48, 0.35, 0.65]),\n",
    "    \"é»‘è²“\": np.array([0.48, 0.58, 0.68, 0.78, 0.38]),\n",
    "}\n",
    "\n",
    "# æ­£è¦åŒ–æ‰€æœ‰å‘é‡\n",
    "for word, vec in halloween_trained_vectors.items():\n",
    "    halloween_trained_vectors[word] = vec / np.linalg.norm(vec)\n",
    "    haunted_space.ghost_vault[word] = halloween_trained_vectors[word]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "for word1, word2 in test_pairs:\n",
    "    similarity = haunted_space.ghost_similarity(word1, word2)\n",
    "    if similarity is not None:\n",
    "        # è½‰æ›ç‚ºç™¾åˆ†æ¯”\n",
    "        percent = (similarity + 1) * 50  # é¤˜å¼¦ç›¸ä¼¼åº¦ç¯„åœ [-1, 1] è½‰ç‚º [0, 100]\n",
    "        \n",
    "        if percent > 70:\n",
    "            emoji = \"ğŸ”¥\"\n",
    "            status = \"éå¸¸æ¥è¿‘\"\n",
    "        elif percent > 50:\n",
    "            emoji = \"âœ¨\"\n",
    "            status = \"æœ‰äº›é—œè¯\"\n",
    "        else:\n",
    "            emoji = \"ğŸ’¨\"\n",
    "            status = \"ç›¸è·ç”šé \"\n",
    "        \n",
    "        print(f\"{emoji} '{word1}' â†”ï¸ '{word2}': {percent:.1f}% ç›¸ä¼¼åº¦ ({status})\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4810d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”® å¹½éˆé„°å±…æœå°‹\n",
    "\n",
    "print(\"\\n\\nğŸ‘» æ‰¾å‡ºæ¯å€‹å¹½éˆæœ€è¦ªå¯†çš„å¤¥ä¼´...\\n\")\n",
    "\n",
    "search_words = [\"å¥³å·«\", \"æ®­å±\", \"å—ç“œ\"]\n",
    "\n",
    "for word in search_words:\n",
    "    print(f\"\\nğŸ” å°‹æ‰¾èˆ‡ '{word}' æœ€æ¥è¿‘çš„å¹½éˆ...\")\n",
    "    neighbors = haunted_space.find_haunted_neighbors(word, top_n=3)\n",
    "    \n",
    "    if neighbors:\n",
    "        print(f\"   ğŸ‘» æœ€æ¥è¿‘çš„å¹½éˆå¤¥ä¼´ï¼š\")\n",
    "        for i, (neighbor, similarity) in enumerate(neighbors, 1):\n",
    "            percent = (similarity + 1) * 50\n",
    "            bar = \"â–ˆ\" * int(percent / 5)\n",
    "            print(f\"   {i}. {neighbor} - {bar} {percent:.1f}%\")\n",
    "    \n",
    "    print(\"   \" + \"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7994bb",
   "metadata": {},
   "source": [
    "## ğŸ§Ÿ ç¬¬äºŒèª²ï¼šæ®­å±ç¥ç¶“ç¶²çµ¡ (Zombie Neural Networks)\n",
    "\n",
    "**ç¥ç¶“ç¶²çµ¡**å°±åƒæ®­å±å¤§è»â€”â€”æ¯å€‹ç¥ç¶“å…ƒéƒ½æ˜¯ä¸€å€‹æ®­å±ï¼Œå®ƒå€‘ï¼š\n",
    "- ğŸ§Ÿ æ¥æ”¶ä¿¡è™Ÿï¼ˆèåˆ°äººè…¦çš„å‘³é“ï¼‰\n",
    "- ğŸ”„ è™•ç†ä¿¡æ¯ï¼ˆæ±ºå®šå¾€å“ªå€‹æ–¹å‘èµ°ï¼‰\n",
    "- ğŸ“¤ å‚³éè¼¸å‡ºï¼ˆç™¼å‡ºæ®­å±å¼è²é€šçŸ¥å…¶ä»–æ®­å±ï¼‰\n",
    "\n",
    "### ğŸ§  ç‚ºä»€éº¼å«ã€Œæ®­å±ã€ç¶²çµ¡ï¼Ÿ\n",
    "\n",
    "1. **å±¤å±¤æ¨é€²**ï¼šå°±åƒæ®­å±æ½®ï¼Œä¸€å±¤å±¤ç¥ç¶“å…ƒä¾åºè™•ç†è³‡è¨Š\n",
    "2. **é›†é«”æ™ºæ…§**ï¼šå–®å€‹æ®­å±ï¼ˆç¥ç¶“å…ƒï¼‰å¾ˆç¬¨ï¼Œä½†æˆç¾¤çµéšŠå°±èƒ½å®Œæˆè¤‡é›œä»»å‹™\n",
    "3. **ä¸æ­»ç‰¹æ€§**ï¼šè¨“ç·´å¥½çš„ç¥ç¶“ç¶²çµ¡å¯ä»¥ä¸€ç›´ä½¿ç”¨ï¼Œæ°¸ä¸ç–²å€¦ï¼\n",
    "4. **åå‘å‚³æ’­**ï¼šå°±åƒæ®­å±ç—…æ¯’å¾€å›å‚³æŸ“ï¼ŒéŒ¯èª¤ä¿¡è™Ÿå¾€å›ä¿®æ­£æ¬Šé‡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37067402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§Ÿ æ®­å±ç¥ç¶“ç¶²çµ¡å¯¦ä½œ\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class ZombieNeuron:\n",
    "    \"\"\"å–®å€‹æ®­å±ç¥ç¶“å…ƒ\"\"\"\n",
    "    \n",
    "    def __init__(self, name, threshold=0.5):\n",
    "        self.name = name\n",
    "        self.threshold = threshold  # æ®­å±çš„ã€Œè¦ºé†’é–¾å€¼ã€\n",
    "        self.is_active = False\n",
    "        \n",
    "    def receive_signal(self, signal_strength):\n",
    "        \"\"\"æ¥æ”¶ä¿¡è™Ÿä¸¦æ±ºå®šæ˜¯å¦è¢«æ¿€æ´»ï¼ˆæ®­å±ç”¦é†’ï¼‰\"\"\"\n",
    "        if signal_strength >= self.threshold:\n",
    "            self.is_active = True\n",
    "            return 1.0  # å®Œå…¨æ¿€æ´»\n",
    "        else:\n",
    "            self.is_active = False\n",
    "            return 0.0  # æ²‰ç¡ä¸­\n",
    "    \n",
    "    def __str__(self):\n",
    "        status = \"ğŸ§Ÿ ç”¦é†’\" if self.is_active else \"ğŸ˜´ æ²‰ç¡\"\n",
    "        return f\"æ®­å± {self.name}: {status}\"\n",
    "\n",
    "\n",
    "class ZombieNeuralNetwork:\n",
    "    \"\"\"æ®­å±ç¥ç¶“ç¶²çµ¡ - ç°¡å–®çš„å‰é¥‹ç¶²çµ¡\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"âš°ï¸ æ­£åœ¨çµ„å»ºæ®­å±å¤§è»...\\n\")\n",
    "        \n",
    "        # å‰µå»ºä¸‰å±¤æ®­å±ç¶²çµ¡\n",
    "        self.input_layer = [\n",
    "            ZombieNeuron(\"è¼¸å…¥æ®­å±_1\", 0.3),\n",
    "            ZombieNeuron(\"è¼¸å…¥æ®­å±_2\", 0.3),\n",
    "            ZombieNeuron(\"è¼¸å…¥æ®­å±_3\", 0.3)\n",
    "        ]\n",
    "        \n",
    "        self.hidden_layer = [\n",
    "            ZombieNeuron(\"éš±è—æ®­å±_A\", 0.5),\n",
    "            ZombieNeuron(\"éš±è—æ®­å±_B\", 0.5)\n",
    "        ]\n",
    "        \n",
    "        self.output_layer = [\n",
    "            ZombieNeuron(\"è¼¸å‡ºæ®­å±\", 0.4)\n",
    "        ]\n",
    "        \n",
    "        # é€£æ¥æ¬Šé‡ï¼ˆæ®­å±ä¹‹é–“çš„è¯ç¹«å¼·åº¦ï¼‰\n",
    "        self.weights_input_hidden = np.random.randn(3, 2) * 0.5\n",
    "        self.weights_hidden_output = np.random.randn(2, 1) * 0.5\n",
    "        \n",
    "        print(\"âœ… æ®­å±å¤§è»é›†çµå®Œç•¢ï¼\")\n",
    "        print(f\"   - è¼¸å…¥å±¤ï¼š{len(self.input_layer)} å€‹æ®­å±\")\n",
    "        print(f\"   - éš±è—å±¤ï¼š{len(self.hidden_layer)} å€‹æ®­å±\")\n",
    "        print(f\"   - è¼¸å‡ºå±¤ï¼š{len(self.output_layer)} å€‹æ®­å±\")\n",
    "        print()\n",
    "    \n",
    "    def forward_propagation(self, input_signals):\n",
    "        \"\"\"å‰å‘å‚³æ’­ - æ®­å±æ½®æ¹§å‘ç›®æ¨™ï¼\"\"\"\n",
    "        print(\"ğŸ§Ÿâ€â™‚ï¸ğŸ§Ÿâ€â™€ï¸ğŸ§Ÿ æ®­å±æ½®é–‹å§‹è¡Œå‹•...\\n\")\n",
    "        \n",
    "        # ç¬¬ä¸€å±¤ï¼šè¼¸å…¥å±¤æ¿€æ´»\n",
    "        print(\"ğŸ“¥ ç¬¬ä¸€æ³¢æ®­å±ç”¦é†’ï¼š\")\n",
    "        input_activations = []\n",
    "        for i, zombie in enumerate(self.input_layer):\n",
    "            activation = zombie.receive_signal(input_signals[i])\n",
    "            input_activations.append(activation)\n",
    "            print(f\"   {zombie}\")\n",
    "        \n",
    "        input_activations = np.array(input_activations)\n",
    "        \n",
    "        # ç¬¬äºŒå±¤ï¼šéš±è—å±¤æ¿€æ´»\n",
    "        print(\"\\nâš¡ ä¿¡è™Ÿå‚³éåˆ°éš±è—å±¤...\")\n",
    "        hidden_signals = np.dot(input_activations, self.weights_input_hidden)\n",
    "        hidden_activations = []\n",
    "        for i, zombie in enumerate(self.hidden_layer):\n",
    "            activation = zombie.receive_signal(hidden_signals[i])\n",
    "            hidden_activations.append(activation)\n",
    "            print(f\"   {zombie}\")\n",
    "        \n",
    "        hidden_activations = np.array(hidden_activations)\n",
    "        \n",
    "        # ç¬¬ä¸‰å±¤ï¼šè¼¸å‡ºå±¤æ¿€æ´»\n",
    "        print(\"\\nğŸ“¤ æœ€çµ‚è¼¸å‡º...\")\n",
    "        output_signal = np.dot(hidden_activations, self.weights_hidden_output)[0]\n",
    "        output_activation = self.output_layer[0].receive_signal(output_signal)\n",
    "        print(f\"   {self.output_layer[0]}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ æœ€çµ‚è¼¸å‡ºå¼·åº¦ï¼š{output_activation:.2f}\")\n",
    "        \n",
    "        return output_activation\n",
    "\n",
    "# ğŸƒ å‰µå»ºä¸¦æ¸¬è©¦æ®­å±ç¶²çµ¡\n",
    "print(\"=\"*60)\n",
    "print(\" \" * 15 + \"ğŸ§Ÿ æ®­å±ç¥ç¶“ç¶²çµ¡å¯¦é©— ğŸ§Ÿ\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "zombie_net = ZombieNeuralNetwork()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ¸¬è©¦æ¡ˆä¾‹ï¼šåµæ¸¬æ˜¯å¦ç‚ºè¬è–ç¯€\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# è¼¸å…¥ç‰¹å¾µï¼š[æœ‰å—ç“œ(0.8), æ˜¯æ™šä¸Š(0.9), æœ‰ç³–æœ(0.7)]\n",
    "test_input = [0.8, 0.9, 0.7]\n",
    "print(f\"è¼¸å…¥ç‰¹å¾µï¼š\")\n",
    "print(f\"  - æœ‰å—ç“œï¼š{test_input[0]}\")\n",
    "print(f\"  - æ˜¯æ™šä¸Šï¼š{test_input[1]}\")\n",
    "print(f\"  - æœ‰ç³–æœï¼š{test_input[2]}\")\n",
    "print()\n",
    "\n",
    "result = zombie_net.forward_propagation(test_input)\n",
    "\n",
    "if result > 0.5:\n",
    "    print(\"\\nğŸƒ çµè«–ï¼šé€™æ˜¯è¬è–ç¯€ï¼æ®­å±å€‘å¾ˆèˆˆå¥®ï¼\")\n",
    "else:\n",
    "    print(\"\\nğŸ˜´ çµè«–ï¼šä¸æ˜¯è¬è–ç¯€ï¼Œæ®­å±å€‘ç¹¼çºŒæ²‰ç¡...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4829023c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c819c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§› å¸è¡€é¬¼æ³¨æ„åŠ›æ©Ÿåˆ¶å¯¦ä½œ\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class VampireAttention:\n",
    "    \"\"\"å¸è¡€é¬¼æ³¨æ„åŠ›æ©Ÿåˆ¶ - é¸æ“‡æ€§å¸å–é‡è¦ä¿¡æ¯\"\"\"\n",
    "    \n",
    "    def __init__(self, name=\"å¾·å¤æ‹‰ä¼¯çˆµ\"):\n",
    "        self.name = name\n",
    "        self.victims = []  # è¢«æ³¨æ„çš„è©å½™ï¼ˆå—å®³è€…ï¼‰\n",
    "        self.attention_scores = []  # æ³¨æ„åŠ›åˆ†æ•¸\n",
    "        \n",
    "    def calculate_attention(self, query, keys):\n",
    "        \"\"\"\n",
    "        è¨ˆç®—æ³¨æ„åŠ›åˆ†æ•¸\n",
    "        query: å¸è¡€é¬¼ç•¶å‰çš„ç›®æ¨™ï¼ˆæƒ³è¦ç†è§£çš„è©ï¼‰\n",
    "        keys: æ‰€æœ‰å¯èƒ½çš„å—å®³è€…ï¼ˆå¥å­ä¸­çš„æ‰€æœ‰è©ï¼‰\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ§› {self.name} é–‹å§‹å°‹æ‰¾çµç‰©...\\n\")\n",
    "        \n",
    "        # è¨ˆç®—ç›¸ä¼¼åº¦åˆ†æ•¸ï¼ˆé»ç©ï¼‰\n",
    "        scores = []\n",
    "        for i, key in enumerate(keys):\n",
    "            # ç°¡å–®çš„ç›¸ä¼¼åº¦è¨ˆç®—\n",
    "            score = np.dot(query, key)\n",
    "            scores.append(score)\n",
    "        \n",
    "        scores = np.array(scores)\n",
    "        \n",
    "        # Softmax - è½‰æ›ç‚ºæ¦‚ç‡åˆ†å¸ƒï¼ˆå¸è¡€é¬¼çš„ã€Œé£¢é¤“æŒ‡æ•¸ã€ï¼‰\n",
    "        exp_scores = np.exp(scores - np.max(scores))  # æ•¸å€¼ç©©å®šæ€§\n",
    "        attention_weights = exp_scores / np.sum(exp_scores)\n",
    "        \n",
    "        self.attention_scores = attention_weights\n",
    "        \n",
    "        return attention_weights\n",
    "    \n",
    "    def visualize_attention(self, words, attention_weights):\n",
    "        \"\"\"è¦–è¦ºåŒ–æ³¨æ„åŠ›åˆ†å¸ƒ\"\"\"\n",
    "        print(\"ğŸ¯ å¸è¡€é¬¼çš„æ³¨æ„åŠ›åˆ†å¸ƒï¼ˆèª°æœ€å¸å¼•ä»–ï¼‰ï¼š\\n\")\n",
    "        \n",
    "        max_weight = np.max(attention_weights)\n",
    "        \n",
    "        for word, weight in zip(words, attention_weights):\n",
    "            # è¨ˆç®—è¦–è¦ºåŒ–é•·åº¦\n",
    "            bar_length = int(weight / max_weight * 30)\n",
    "            bar = \"ğŸ©¸\" * bar_length\n",
    "            percentage = weight * 100\n",
    "            \n",
    "            # åˆ¤æ–·æ³¨æ„åŠ›ç­‰ç´š\n",
    "            if percentage > 30:\n",
    "                emoji = \"ğŸ§›\"\n",
    "                status = \"ä¸»è¦ç›®æ¨™\"\n",
    "            elif percentage > 10:\n",
    "                emoji = \"ğŸ‘€\"\n",
    "                status = \"æ¬¡è¦ç›®æ¨™\"\n",
    "            else:\n",
    "                emoji = \"ğŸ’¨\"\n",
    "                status = \"å¿½ç•¥\"\n",
    "            \n",
    "            print(f\"{emoji} '{word}': {bar} {percentage:.1f}% ({status})\")\n",
    "    \n",
    "    def extract_blood(self, values, attention_weights):\n",
    "        \"\"\"\n",
    "        å¸å–ä¿¡æ¯ï¼ˆåŠ æ¬Šæ±‚å’Œï¼‰\n",
    "        values: æ¯å€‹è©çš„å¯¦éš›ä¿¡æ¯å…§å®¹\n",
    "        attention_weights: æ³¨æ„åŠ›æ¬Šé‡\n",
    "        \"\"\"\n",
    "        # åŠ æ¬Šå¹³å‡\n",
    "        extracted_info = np.zeros_like(values[0])\n",
    "        for value, weight in zip(values, attention_weights):\n",
    "            extracted_info += weight * value\n",
    "        \n",
    "        return extracted_info\n",
    "\n",
    "\n",
    "# ğŸƒ å¯¦é©—ï¼šå¸è¡€é¬¼ç†è§£å¥å­\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" \" * 20 + \"ğŸ§› å¸è¡€é¬¼æ³¨æ„åŠ›å¯¦é©— ğŸ§›\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# æ¨¡æ“¬ä¸€å€‹å¥å­ï¼š\"è¬è–ç¯€çš„å¤œæ™šï¼Œå—ç“œç‡ˆç…§äº®äº†é»‘æš—\"\n",
    "sentence = [\"è¬è–ç¯€\", \"çš„\", \"å¤œæ™š\", \"å—ç“œç‡ˆ\", \"ç…§äº®\", \"äº†\", \"é»‘æš—\"]\n",
    "\n",
    "# ç‚ºæ¯å€‹è©å‰µå»ºç°¡å–®çš„å‘é‡è¡¨ç¤ºï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­æœƒç”¨è¨“ç·´å¥½çš„è©å‘é‡ï¼‰\n",
    "word_vectors = {\n",
    "    \"è¬è–ç¯€\": np.array([0.9, 0.8, 0.2]),\n",
    "    \"çš„\": np.array([0.1, 0.1, 0.1]),\n",
    "    \"å¤œæ™š\": np.array([0.2, 0.1, 0.9]),\n",
    "    \"å—ç“œç‡ˆ\": np.array([0.85, 0.75, 0.3]),\n",
    "    \"ç…§äº®\": np.array([0.7, 0.3, 0.6]),\n",
    "    \"äº†\": np.array([0.1, 0.1, 0.1]),\n",
    "    \"é»‘æš—\": np.array([0.1, 0.2, 0.95])\n",
    "}\n",
    "\n",
    "print(\"ğŸ“– åŸå¥ï¼šã€Œ\" + \" \".join(sentence) + \"ã€\\n\")\n",
    "print(\"-\"*70 + \"\\n\")\n",
    "\n",
    "# å‰µå»ºå¸è¡€é¬¼\n",
    "dracula = VampireAttention(\"å¾·å¤æ‹‰ä¼¯çˆµ\")\n",
    "\n",
    "# å‡è¨­æˆ‘å€‘æƒ³ç†è§£ã€Œè¬è–ç¯€ã€é€™å€‹è©çš„ä¸Šä¸‹æ–‡\n",
    "query_word = \"è¬è–ç¯€\"\n",
    "query_vector = word_vectors[query_word]\n",
    "\n",
    "print(f\"ğŸ¯ æŸ¥è©¢è©ï¼ˆå¸è¡€é¬¼çš„åˆå§‹ç›®æ¨™ï¼‰ï¼š'{query_word}'\\n\")\n",
    "\n",
    "# æº–å‚™æ‰€æœ‰è©çš„å‘é‡\n",
    "keys = [word_vectors[w] for w in sentence]\n",
    "values = keys  # åœ¨é€™å€‹ç°¡åŒ–ä¾‹å­ä¸­ï¼Œkeys å’Œ values ç›¸åŒ\n",
    "\n",
    "# è¨ˆç®—æ³¨æ„åŠ›\n",
    "attention_weights = dracula.calculate_attention(query_vector, keys)\n",
    "\n",
    "# è¦–è¦ºåŒ–\n",
    "dracula.visualize_attention(sentence, attention_weights)\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "\n",
    "# å¸å–ä¿¡æ¯\n",
    "extracted_info = dracula.extract_blood(values, attention_weights)\n",
    "\n",
    "print(\"\\nğŸ©¸ å¸è¡€é¬¼å¸å–çš„ä¿¡æ¯ï¼ˆåŠ æ¬Šå‘é‡ï¼‰ï¼š\")\n",
    "print(f\"   {extracted_info}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ è§£é‡‹ï¼š\")\n",
    "print(\"   - æ³¨æ„åŠ›æœ€é«˜çš„è©æœƒè¢«é‡é»é—œæ³¨\")\n",
    "print(\"   - ã€Œçš„ã€ã€ã€Œäº†ã€ç­‰è™›è©æ³¨æ„åŠ›è¼ƒä½\")\n",
    "print(\"   - ç›¸é—œåè©ï¼ˆå—ç“œç‡ˆï¼‰ç²å¾—è¼ƒé«˜æ³¨æ„åŠ›\")\n",
    "print(\"   - æœ€çµ‚è¼¸å‡ºæ˜¯æ‰€æœ‰è©çš„åŠ æ¬Šçµ„åˆ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052890f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ•·ï¸ èœ˜è››ç¶²èªè¨€æ¨¡å‹\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "class SpiderWebLanguageModel:\n",
    "    \"\"\"èœ˜è››ç¶² N-gram èªè¨€æ¨¡å‹\"\"\"\n",
    "    \n",
    "    def __init__(self, n=2):\n",
    "        \"\"\"\n",
    "        n: N-gram çš„ Nï¼ˆèœ˜è››çš„è¨˜æ†¶é•·åº¦ï¼‰\n",
    "        n=2: bigramï¼ˆè¨˜ä½å‰1å€‹è©ï¼‰\n",
    "        n=3: trigramï¼ˆè¨˜ä½å‰2å€‹è©ï¼‰\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.web = defaultdict(list)  # èœ˜è››ç¶²çµæ§‹\n",
    "        self.start_words = []  # ç¶²çš„å…¥å£é»\n",
    "        \n",
    "    def build_web(self, texts):\n",
    "        \"\"\"ç·¨ç¹”èœ˜è››ç¶²ï¼ˆè¨“ç·´æ¨¡å‹ï¼‰\"\"\"\n",
    "        print(f\"ğŸ•·ï¸ èœ˜è››é–‹å§‹ç·¨ç¹” {self.n}-gram ç¶²...\\n\")\n",
    "        \n",
    "        for text in texts:\n",
    "            words = text.split()\n",
    "            \n",
    "            # è¨˜éŒ„é–‹é ­è©\n",
    "            if len(words) >= self.n:\n",
    "                self.start_words.append(tuple(words[:self.n-1]))\n",
    "            \n",
    "            # å»ºç«‹ N-gram é€£æ¥\n",
    "            for i in range(len(words) - self.n + 1):\n",
    "                # å–å‰ n-1 å€‹è©ä½œç‚ºã€Œä¸Šä¸‹æ–‡ã€\n",
    "                context = tuple(words[i:i+self.n-1])\n",
    "                next_word = words[i+self.n-1]\n",
    "                \n",
    "                # åœ¨èœ˜è››ç¶²ä¸­å»ºç«‹é€£æ¥\n",
    "                self.web[context].append(next_word)\n",
    "        \n",
    "        print(f\"âœ… èœ˜è››ç¶²ç·¨ç¹”å®Œæˆï¼\")\n",
    "        print(f\"   - ç¶²çµ¡ç¯€é»æ•¸ï¼š{len(self.web)}\")\n",
    "        print(f\"   - å…¥å£é»æ•¸ï¼š{len(self.start_words)}\")\n",
    "        \n",
    "    def predict_next(self, context):\n",
    "        \"\"\"é æ¸¬ä¸‹ä¸€å€‹è©ï¼ˆèœ˜è››çˆ¬è¡Œï¼‰\"\"\"\n",
    "        context_tuple = tuple(context.split())\n",
    "        \n",
    "        if context_tuple in self.web:\n",
    "            # éš¨æ©Ÿé¸æ“‡ä¸€å€‹å¯èƒ½çš„ä¸‹ä¸€å€‹è©\n",
    "            next_words = self.web[context_tuple]\n",
    "            return random.choice(next_words)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def generate_sentence(self, max_words=15):\n",
    "        \"\"\"ç”Ÿæˆå¥å­ï¼ˆèœ˜è››åœ¨ç¶²ä¸Šçˆ¬è¡Œï¼‰\"\"\"\n",
    "        if not self.start_words:\n",
    "            return \"ğŸ•¸ï¸ ç¶²é‚„æ²’ç·¨å¥½...\"\n",
    "        \n",
    "        # éš¨æ©Ÿé¸æ“‡ä¸€å€‹èµ·é»\n",
    "        current_words = list(random.choice(self.start_words))\n",
    "        \n",
    "        for _ in range(max_words):\n",
    "            # å–æœ€å¾Œ n-1 å€‹è©ä½œç‚ºä¸Šä¸‹æ–‡\n",
    "            context = tuple(current_words[-(self.n-1):])\n",
    "            \n",
    "            # é æ¸¬ä¸‹ä¸€å€‹è©\n",
    "            if context in self.web:\n",
    "                next_word = random.choice(self.web[context])\n",
    "                current_words.append(next_word)\n",
    "            else:\n",
    "                # ç¶²æ–·äº†ï¼Œåœæ­¢ç”Ÿæˆ\n",
    "                break\n",
    "        \n",
    "        return \" \".join(current_words)\n",
    "    \n",
    "    def show_web_structure(self, sample_size=5):\n",
    "        \"\"\"å±•ç¤ºèœ˜è››ç¶²çš„éƒ¨åˆ†çµæ§‹\"\"\"\n",
    "        print(\"\\nğŸ•¸ï¸ èœ˜è››ç¶²çµæ§‹æ¨£æœ¬ï¼ˆéƒ¨åˆ†é€£æ¥ï¼‰ï¼š\\n\")\n",
    "        \n",
    "        items = list(self.web.items())[:sample_size]\n",
    "        \n",
    "        for context, next_words in items:\n",
    "            context_str = \" \".join(context)\n",
    "            print(f\"ğŸ“ '{context_str}' â†’ å¯èƒ½æ¥ï¼š\")\n",
    "            \n",
    "            # çµ±è¨ˆæ¯å€‹è©å‡ºç¾çš„æ¬¡æ•¸\n",
    "            word_counts = {}\n",
    "            for word in next_words:\n",
    "                word_counts[word] = word_counts.get(word, 0) + 1\n",
    "            \n",
    "            for word, count in word_counts.items():\n",
    "                probability = count / len(next_words) * 100\n",
    "                print(f\"      ğŸ•·ï¸ '{word}' (æ©Ÿç‡: {probability:.1f}%)\")\n",
    "            print()\n",
    "\n",
    "\n",
    "# ğŸƒ å¯¦é©—ï¼šè¨“ç·´è¬è–ç¯€èªè¨€æ¨¡å‹\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" \" * 18 + \"ğŸ•·ï¸ èœ˜è››ç¶²èªè¨€æ¨¡å‹å¯¦é©— ğŸ•·ï¸\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# è¨“ç·´æ•¸æ“šï¼šè¬è–ç¯€ç›¸é—œå¥å­\n",
    "halloween_corpus = [\n",
    "    \"è¬è–ç¯€çš„å¤œæ™š å—ç“œç‡ˆç…§äº®é»‘æš—\",\n",
    "    \"è¬è–ç¯€çš„æ´¾å° å­©å­å€‘ç©¿è‘—å¯æ€•çš„æœè£\",\n",
    "    \"å—ç“œç‡ˆåœ¨ è¬è–ç¯€ æ˜¯é‡è¦çš„è±¡å¾µ\",\n",
    "    \"é»‘æš—çš„å¤œæ™š å¸è¡€é¬¼å‡ºæ²’åœ¨è¡—é“ä¸Š\",\n",
    "    \"å¯æ€•çš„æœè£ æ˜¯è¬è–ç¯€çš„å‚³çµ±\",\n",
    "    \"è¬è–ç¯€çš„ç³–æœ è®“å­©å­å€‘èˆˆå¥®ä¸å·²\",\n",
    "    \"é¬¼é­‚åœ¨è¬è–ç¯€çš„å¤œæ™šå‡ºç¾\",\n",
    "    \"å—ç“œç‡ˆçš„å…‰èŠ’åœ¨é»‘æš—ä¸­é–ƒçˆ\",\n",
    "    \"å­©å­å€‘åœ¨è¬è–ç¯€æ”¶é›†ç³–æœ\",\n",
    "    \"å¯æ€•çš„è£é£¾ å¸ƒæ»¿äº†æ•´å€‹è¡—é“\"\n",
    "]\n",
    "\n",
    "# å‰µå»ºä¸¦è¨“ç·´æ¨¡å‹\n",
    "spider = SpiderWebLanguageModel(n=2)  # Bigram æ¨¡å‹\n",
    "spider.build_web(halloween_corpus)\n",
    "\n",
    "# å±•ç¤ºç¶²çµ¡çµæ§‹\n",
    "spider.show_web_structure(sample_size=8)\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"\\nğŸ² è®“èœ˜è››ç”Ÿæˆä¸€äº›è¬è–ç¯€å¥å­ï¼š\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    sentence = spider.generate_sentence(max_words=12)\n",
    "    print(f\"{i+1}. ğŸ•¸ï¸ {sentence}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "print(\"\\nğŸ’¡ èªè¨€æ¨¡å‹çš„æ‡‰ç”¨ï¼š\")\n",
    "print(\"   âœ… è‡ªå‹•è£œå…¨ï¼ˆæ‰‹æ©Ÿè¼¸å…¥æ³•ï¼‰\")\n",
    "print(\"   âœ… æ©Ÿå™¨ç¿»è­¯\")\n",
    "print(\"   âœ… æ–‡æœ¬ç”Ÿæˆï¼ˆChatGPTã€GPT-4ï¼‰\")\n",
    "print(\"   âœ… èªéŸ³è­˜åˆ¥\")\n",
    "print(\"   âœ… æ‹¼å¯«æª¢æŸ¥\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ad599",
   "metadata": {},
   "source": [
    "## ğŸƒ ç¬¬äº”èª²ï¼šå·«å¸«çš„è©›å’’åˆ†é¡å™¨ (Witch's Curse Classifier)\n",
    "\n",
    "**æ–‡æœ¬åˆ†é¡**æ˜¯ NLP ä¸­æœ€å¯¦ç”¨çš„æ‡‰ç”¨ä¹‹ä¸€ï¼å°±åƒå¥³å·«å€åˆ†ä¸åŒçš„è©›å’’é¡å‹ã€‚\n",
    "\n",
    "### ğŸ”® æ‡‰ç”¨å ´æ™¯\n",
    "- ğŸ“§ åƒåœ¾éƒµä»¶åµæ¸¬ï¼ˆæƒ¡æ„è©›å’’ vs æ­£å¸¸éƒµä»¶ï¼‰\n",
    "- ğŸ’¬ æƒ…æ„Ÿåˆ†æï¼ˆå¿«æ¨‚è©›å’’ vs æ‚²å‚·è©›å’’ï¼‰\n",
    "- ğŸ·ï¸ æ–°èåˆ†é¡ï¼ˆæ”¿æ²»è©›å’’ã€é«”è‚²è©›å’’ã€å¨›æ¨‚è©›å’’ï¼‰\n",
    "- ğŸ¤– æ„åœ–è­˜åˆ¥ï¼ˆèŠå¤©æ©Ÿå™¨äººç†è§£ç”¨æˆ¶æƒ³è¦ä»€éº¼ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeceb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§™â€â™€ï¸ å¥³å·«çš„è©›å’’åˆ†é¡å™¨\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "class WitchCurseClassifier:\n",
    "    \"\"\"å¥³å·«çš„è©›å’’åˆ†é¡å™¨ - ç°¡å–®çš„æ¨¸ç´ è²è‘‰æ–¯åˆ†é¡å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.word_counts = {}  # æ¯å€‹é¡åˆ¥çš„è©é »\n",
    "        self.class_counts = {}  # æ¯å€‹é¡åˆ¥çš„æ–‡æª”æ•¸\n",
    "        self.vocabulary = set()  # è©å½™è¡¨\n",
    "        \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"é è™•ç†æ–‡æœ¬ï¼ˆå¥³å·«çš„å’’èªæº–å‚™ï¼‰\"\"\"\n",
    "        # è½‰å°å¯«ã€åˆ†è©\n",
    "        words = text.lower().split()\n",
    "        return words\n",
    "    \n",
    "    def train(self, texts, labels):\n",
    "        \"\"\"è¨“ç·´åˆ†é¡å™¨ï¼ˆå¥³å·«å­¸ç¿’è©›å’’ï¼‰\"\"\"\n",
    "        print(\"ğŸ”® å¥³å·«é–‹å§‹å­¸ç¿’è©›å’’çš„å¥§ç§˜...\\n\")\n",
    "        \n",
    "        for text, label in zip(texts, labels):\n",
    "            words = self.preprocess(text)\n",
    "            \n",
    "            # æ›´æ–°è©å½™è¡¨\n",
    "            self.vocabulary.update(words)\n",
    "            \n",
    "            # åˆå§‹åŒ–é¡åˆ¥è¨ˆæ•¸\n",
    "            if label not in self.word_counts:\n",
    "                self.word_counts[label] = Counter()\n",
    "                self.class_counts[label] = 0\n",
    "            \n",
    "            # çµ±è¨ˆè©é »\n",
    "            self.word_counts[label].update(words)\n",
    "            self.class_counts[label] += 1\n",
    "        \n",
    "        print(\"âœ… å­¸ç¿’å®Œæˆï¼\")\n",
    "        print(f\"   - è©›å’’é¡å‹æ•¸ï¼š{len(self.class_counts)}\")\n",
    "        print(f\"   - è©å½™é‡ï¼š{len(self.vocabulary)}\")\n",
    "        print(f\"   - è¨“ç·´æ¨£æœ¬æ•¸ï¼š{sum(self.class_counts.values())}\")\n",
    "        \n",
    "        for curse_type, count in self.class_counts.items():\n",
    "            print(f\"     â€¢ {curse_type}ï¼š{count} å€‹æ¨£æœ¬\")\n",
    "    \n",
    "    def predict(self, text):\n",
    "        \"\"\"é æ¸¬æ–‡æœ¬é¡åˆ¥ï¼ˆè­˜åˆ¥è©›å’’é¡å‹ï¼‰\"\"\"\n",
    "        words = self.preprocess(text)\n",
    "        \n",
    "        scores = {}\n",
    "        total_docs = sum(self.class_counts.values())\n",
    "        \n",
    "        for label in self.class_counts:\n",
    "            # è¨ˆç®—å…ˆé©—æ¦‚ç‡ P(class)\n",
    "            prior = self.class_counts[label] / total_docs\n",
    "            \n",
    "            # è¨ˆç®—ä¼¼ç„¶æ¦‚ç‡ P(words|class)\n",
    "            likelihood = 1.0\n",
    "            total_words = sum(self.word_counts[label].values())\n",
    "            vocab_size = len(self.vocabulary)\n",
    "            \n",
    "            for word in words:\n",
    "                # Laplace å¹³æ»‘\n",
    "                word_count = self.word_counts[label].get(word, 0)\n",
    "                word_prob = (word_count + 1) / (total_words + vocab_size)\n",
    "                likelihood *= word_prob\n",
    "            \n",
    "            # å¾Œé©—æ¦‚ç‡ï¼ˆå–å°æ•¸é¿å…ä¸‹æº¢ï¼‰\n",
    "            scores[label] = prior * likelihood\n",
    "        \n",
    "        # è¿”å›åˆ†æ•¸æœ€é«˜çš„é¡åˆ¥\n",
    "        return max(scores.items(), key=lambda x: x[1])\n",
    "    \n",
    "    def show_top_words(self, label, top_n=5):\n",
    "        \"\"\"é¡¯ç¤ºæŸé¡è©›å’’çš„ç‰¹å¾µè©\"\"\"\n",
    "        if label not in self.word_counts:\n",
    "            return\n",
    "        \n",
    "        top_words = self.word_counts[label].most_common(top_n)\n",
    "        print(f\"\\nğŸ”® '{label}' è©›å’’çš„ç‰¹å¾µè©ï¼š\")\n",
    "        for word, count in top_words:\n",
    "            print(f\"   âœ¨ '{word}': {count} æ¬¡\")\n",
    "\n",
    "\n",
    "# ğŸƒ å¯¦é©—ï¼šè¨“ç·´è©›å’’åˆ†é¡å™¨\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" \" * 16 + \"ğŸ§™â€â™€ï¸ å¥³å·«çš„è©›å’’åˆ†é¡å™¨å¯¦é©— ğŸ§™â€â™€ï¸\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# è¨“ç·´æ•¸æ“šï¼šä¸åŒé¡å‹çš„è©›å’’\n",
    "curse_texts = [\n",
    "    # ææ€–è©›å’’\n",
    "    \"é»‘æš— é¬¼é­‚ ææ€– åš‡äºº å¯æ€• é©šæ‚š æ­»äº¡ éª·é«\",\n",
    "    \"å¸è¡€é¬¼ æ®­å± æ€ªç‰© é‚ªæƒ¡ ææ€– è¡€è…¥ å¢“åœ°\",\n",
    "    \"å°–å« ææ€– é»‘æš— å™©å¤¢ ææ‡¼ é¡«æŠ–\",\n",
    "    \n",
    "    # æ­¡æ¨‚è©›å’’\n",
    "    \"ç³–æœ æ´¾å° æ­¡ç¬‘ å¿«æ¨‚ æ…¶ç¥ éŠæˆ² æœ‹å‹ é–‹å¿ƒ\",\n",
    "    \"ç¦®ç‰© éŸ³æ¨‚ èˆè¹ˆ æ­¡æ¨‚ æ…¶å…¸ ç¾é£Ÿ å¿«æ¨‚\",\n",
    "    \"æ­¡ç¬‘ ç©è€ æ…¶ç¥ æ´¾å° é–‹å¿ƒ æ„‰å¿«\",\n",
    "    \n",
    "    # é­”æ³•è©›å’’\n",
    "    \"é­”æ³• å’’èª é­”æ– è®Šèº« é£›è¡Œ é­”è—¥ æ³•è¡“ ç¥ç§˜\",\n",
    "    \"é­”æ³•æ›¸ å’’èª å·«å¸« é­”åŠ› è®ŠåŒ– æ³•è¡“ ç¥å¥‡\",\n",
    "    \"é­”æ³• é­”è—¥ å’’èª é­”åŠ› è®Šèº« ç¥ç§˜ æ–½æ³•\"\n",
    "]\n",
    "\n",
    "curse_labels = [\n",
    "    \"ææ€–\", \"ææ€–\", \"ææ€–\",\n",
    "    \"æ­¡æ¨‚\", \"æ­¡æ¨‚\", \"æ­¡æ¨‚\",\n",
    "    \"é­”æ³•\", \"é­”æ³•\", \"é­”æ³•\"\n",
    "]\n",
    "\n",
    "# å‰µå»ºä¸¦è¨“ç·´åˆ†é¡å™¨\n",
    "witch = WitchCurseClassifier()\n",
    "witch.train(curse_texts, curse_labels)\n",
    "\n",
    "# é¡¯ç¤ºæ¯é¡è©›å’’çš„ç‰¹å¾µè©\n",
    "for label in set(curse_labels):\n",
    "    witch.show_top_words(label, top_n=5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nğŸ”® æ¸¬è©¦å¥³å·«çš„åˆ†é¡èƒ½åŠ›ï¼š\\n\")\n",
    "\n",
    "# æ¸¬è©¦æ¡ˆä¾‹\n",
    "test_cases = [\n",
    "    \"é€™è£¡æœ‰å¾ˆå¤šé¬¼é­‚å’Œéª·é« éå¸¸ææ€–\",\n",
    "    \"æˆ‘å€‘åœ¨æ´¾å°ä¸Šç©éŠæˆ² åƒç³–æœ å¾ˆé–‹å¿ƒ\",\n",
    "    \"å¥³å·«ç”¨é­”æ–æ–½å±•äº†ç¥ç§˜çš„å’’èª\",\n",
    "    \"é»‘æš—çš„å¢“åœ°è£¡å‚³ä¾†å°–å«è²\",\n",
    "    \"æœ‹å‹å€‘ä¸€èµ·æ…¶ç¥ æ­¡ç¬‘ä¸åœ\"\n",
    "]\n",
    "\n",
    "for i, test_text in enumerate(test_cases, 1):\n",
    "    predicted_label, score = witch.predict(test_text)\n",
    "    \n",
    "    # é¸æ“‡ emoji\n",
    "    emoji_map = {\n",
    "        \"ææ€–\": \"ğŸ‘»\",\n",
    "        \"æ­¡æ¨‚\": \"ğŸ‰\",\n",
    "        \"é­”æ³•\": \"ğŸ”®\"\n",
    "    }\n",
    "    emoji = emoji_map.get(predicted_label, \"â“\")\n",
    "    \n",
    "    print(f\"{i}. æ¸¬è©¦æ–‡æœ¬ï¼šã€Œ{test_text}ã€\")\n",
    "    print(f\"   {emoji} é æ¸¬ï¼š{predicted_label} (ä¿¡å¿ƒåº¦: {score:.6f})\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38a9e9",
   "metadata": {},
   "source": [
    "## ğŸ“ è¶…è‡ªç„¶ NLP ç¸½çµ\n",
    "\n",
    "æ­å–œä½ å®Œæˆäº†**è¶…è‡ªç„¶èªè¨€è™•ç†**çš„è©­ç•°ä¹‹æ—…ï¼\n",
    "\n",
    "### ğŸ“š ä½ å­¸åˆ°äº†ä»€éº¼ï¼š\n",
    "\n",
    "1. **ğŸ‘» å¹½éˆè©å‘é‡ (Ghost Word Vectors)**\n",
    "   - å°‡æ–‡å­—è½‰æ›ç‚ºå‘é‡ç©ºé–“ä¸­çš„é»\n",
    "   - è¨ˆç®—è©å½™ç›¸ä¼¼åº¦\n",
    "   - Word2Vecã€GloVe ç­‰è©å‘é‡æŠ€è¡“çš„åŸºç¤\n",
    "\n",
    "2. **ğŸ§Ÿ æ®­å±ç¥ç¶“ç¶²çµ¡ (Zombie Neural Networks)**\n",
    "   - ç¥ç¶“å…ƒçš„æ¿€æ´»æ©Ÿåˆ¶\n",
    "   - å‰å‘å‚³æ’­éç¨‹\n",
    "   - å¤šå±¤ç¥ç¶“ç¶²çµ¡çš„å”ä½œ\n",
    "\n",
    "3. **ğŸ§› å¸è¡€é¬¼æ³¨æ„åŠ›æ©Ÿåˆ¶ (Vampire Attention Mechanism)**\n",
    "   - é¸æ“‡æ€§é—œæ³¨é‡è¦ä¿¡æ¯\n",
    "   - Softmax å’Œæ³¨æ„åŠ›æ¬Šé‡\n",
    "   - Transformer æ¨¡å‹çš„æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "4. **ğŸ•·ï¸ èœ˜è››ç¶²èªè¨€æ¨¡å‹ (Web Language Models)**\n",
    "   - N-gram èªè¨€æ¨¡å‹\n",
    "   - æ–‡æœ¬ç”ŸæˆåŸç†\n",
    "   - çµ±è¨ˆå¼èªè¨€å»ºæ¨¡\n",
    "\n",
    "5. **ğŸ§™â€â™€ï¸ å¥³å·«çš„è©›å’’åˆ†é¡å™¨ (Witch's Curse Classifier)**\n",
    "   - æ¨¸ç´ è²è‘‰æ–¯åˆ†é¡å™¨\n",
    "   - æ–‡æœ¬åˆ†é¡æ‡‰ç”¨\n",
    "   - ç‰¹å¾µæå–èˆ‡é æ¸¬\n",
    "\n",
    "### ğŸš€ æ¥ä¸‹ä¾†çš„å­¸ç¿’æ–¹å‘ï¼š\n",
    "\n",
    "- ğŸ¤– **Transformer æ¶æ§‹**ï¼šæ·±å…¥å­¸ç¿’ BERTã€GPT ç­‰æ¨¡å‹\n",
    "- ğŸ—£ï¸ **èªéŸ³è­˜åˆ¥ (ASR)**ï¼šå°‡è²éŸ³è½‰æ›ç‚ºæ–‡å­—\n",
    "- ğŸŒ **æ©Ÿå™¨ç¿»è­¯ (MT)**ï¼šè·¨èªè¨€çš„é­”æ³•æ©‹æ¨‘\n",
    "- ğŸ“Š **ä¿¡æ¯æŠ½å– (IE)**ï¼šå¾æ–‡æœ¬ä¸­æŒ–æ˜çµæ§‹åŒ–æ•¸æ“š\n",
    "- ğŸ’¬ **å°è©±ç³»çµ±**ï¼šæ‰“é€ ä½ è‡ªå·±çš„ AI åŠ©æ‰‹\n",
    "\n",
    "### ğŸ“– æ¨è–¦è³‡æºï¼š\n",
    "\n",
    "- ğŸ“˜ [Speech and Language Processing (Jurafsky & Martin)](https://web.stanford.edu/~jurafsky/slp3/)\n",
    "- ğŸ“— [Dive into Deep Learning](https://d2l.ai/)\n",
    "- ğŸ“™ [Hugging Face NLP Course](https://huggingface.co/learn/nlp-course/)\n",
    "- ğŸ“• [Fast.ai NLP Course](https://www.fast.ai/)\n",
    "\n",
    "---\n",
    "\n",
    "**è¨˜ä½ï¼šNLP å°±åƒé­”æ³•ï¼Œçœ‹ä¼¼è©­ç•°ï¼Œå¯¦å‰‡æœ‰è·¡å¯å¾ªï¼** ğŸ”®âœ¨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸƒ æœ€å¾Œçš„è¬è–ç¯€ç¥ç¦\n",
    "\n",
    "import random\n",
    "\n",
    "print(\"\\n\" + \"ğŸƒ\" * 20)\n",
    "print(\"\\n\" + \" \" * 15 + \"ğŸ‘» è¬è–ç¯€å¿«æ¨‚ï¼ ğŸ‘»\")\n",
    "print(\" \" * 10 + \"Happy Supernatural NLP Learning!\")\n",
    "print(\"\\n\" + \"ğŸƒ\" * 20)\n",
    "\n",
    "halloween_nlp_quotes = [\n",
    "    \"åœ¨ NLP çš„ä¸–ç•Œè£¡ï¼Œæ¯å€‹è©éƒ½æ˜¯ä¸€å€‹å¹½éˆï¼Œç­‰å¾…è¢«ç†è§£ã€‚\",\n",
    "    \"æ©Ÿå™¨å­¸ç¿’å°±åƒé­”æ³•ï¼Œæ•¸æ“šå°±æ˜¯é­”æ³•ææ–™ã€‚\",\n",
    "    \"æ³¨æ„åŠ›æ©Ÿåˆ¶ï¼šå¸è¡€é¬¼æ•™æœƒæˆ‘å€‘ï¼Œå°ˆæ³¨æ–¼é‡è¦çš„äº‹ç‰©ã€‚\",\n",
    "    \"ç¥ç¶“ç¶²çµ¡ï¼šæ®­å±å¤§è»æ•™æœƒæˆ‘å€‘ï¼Œåœ˜éšŠå”ä½œçš„åŠ›é‡ã€‚\",\n",
    "    \"è©å‘é‡ï¼šæŠŠæŠ½è±¡çš„éˆé­‚ï¼Œè½‰åŒ–ç‚ºå…·é«”çš„æ•¸å­—ã€‚\"\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ’€ \" + random.choice(halloween_nlp_quotes) + \" ğŸ’€\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ”® ç¹¼çºŒä½ çš„ NLP é­”æ³•ä¹‹æ—…ï¼\")\n",
    "print(\"ğŸ§™â€â™€ï¸ é¡˜ä½ çš„æ¨¡å‹æº–ç¢ºï¼Œæ•¸æ“šè±å¯Œï¼\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\" + \" \" * 25 + \"ğŸ‘» THE END ğŸ‘»\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
